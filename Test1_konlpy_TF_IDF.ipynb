{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 분석을 위한 3x3 matrix를 만들었습니다.\n",
      "[[1.         0.62111188 0.2554899 ]\n",
      " [0.62111188 1.         0.51770886]\n",
      " [0.2554899  0.51770886 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "mydoclist = ['find what you love', 'do what you love', \"don't do what you hate\"]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(mydoclist)\n",
    "\n",
    "documnet_distance = (tfidf_matrix * tfidf_matrix.T)\n",
    "\n",
    "print('유사도 분석을 위한 ' + str(documnet_distance.get_shape()[0]) + 'x' + str(documnet_distance.get_shape()[1]) + ' matrix를 만들었습니다.')\n",
    "print(documnet_distance.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 분석을 위한 3x3 matrix를 만들었습니다.\n",
      "[[1.       0.208199 0.      ]\n",
      " [0.208199 1.       0.208199]\n",
      " [0.       0.208199 1.      ]]\n"
     ]
    }
   ],
   "source": [
    "mydoclist2 = ['영희가 좋아하는 사람은 철수다.', '철수를 영희가 좋아한다.', '영희는 철수를 좋아하고 있다.']\n",
    "\n",
    "tfidf_vectorizer2 = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix2 = tfidf_vectorizer2.fit_transform(mydoclist2)\n",
    "\n",
    "documnet_distance2 = (tfidf_matrix2 * tfidf_matrix2.T)\n",
    "\n",
    "print('유사도 분석을 위한 ' + str(documnet_distance2.get_shape()[0]) + 'x' + str(documnet_distance2.get_shape()[1]) + ' matrix를 만들었습니다.')\n",
    "print(documnet_distance2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 : ['영희', '와', '철수', '는', '백구', '를', '산책', '시키', '기', '위하', '어', '한강', '에', '가', '었', '다', '.', '한강', '에', '도착', '하', '여', '누렁이', '를', '만나', '었', '다', '.']\n",
      "명사 : ['영희', '철수', '백구', '산책', '한강', '도착', '누렁이']\n",
      "품사 : [('영희', 'NNP'), ('와', 'JKM'), ('철수', 'NNG'), ('는', 'JX'), ('백구', 'NNG'), ('를', 'JKO'), ('산책', 'NNG'), ('시키', 'XSV'), ('기', 'ETN'), ('위하', 'VV'), ('어', 'ECS'), ('한강', 'NNP'), ('에', 'JKM'), ('가', 'VV'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF'), ('한강', 'NNP'), ('에', 'JKM'), ('도착', 'NNG'), ('하', 'XSV'), ('여', 'ECS'), ('누렁이', 'NNG'), ('를', 'JKO'), ('만나', 'VV'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "kkma = Kkma()\n",
    "sentence = u'영희와 철수는 백구를 산책시키기 위해 한강에 갔다. 한강에 도착하여 누렁이를 만났다.'\n",
    "print('형태소 : ' + str(kkma.morphs(sentence)))\n",
    "\n",
    "print('명사 : ' + str(kkma.nouns(sentence)))\n",
    "\n",
    "print('품사 : ' + str(kkma.pos(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['영희', '사랑', '강아지', '백구', '산책']\n",
      "['철수', '사랑', '소', '누렁이', '운동']\n",
      "['영희', '철수', '소', '강아지', '산책', '운동']\n",
      "doc1 : 영희 사랑 강아지 백구 산책 \n",
      "doc2 : 철수 사랑 소 누렁이 운동 \n",
      "doc3 : 영희 철수 소 강아지 산책 운동 \n"
     ]
    }
   ],
   "source": [
    "mydoclist = ['영희가 사랑하는 강아지 백구를 산책시키고 있다.', '철수가 사랑하는 소 누렁이를 운동시키고 있다.', '영희와 철수는 소와 강아지를 산책 및 운동시키고 있다.']\n",
    "\n",
    "kkma = Kkma()\n",
    "\n",
    "doc_nouns_list=[]\n",
    "\n",
    "for doc in mydoclist:\n",
    "    nouns = kkma.nouns(doc) #nouns = 영희, 사랑, 강아지, 백구, 산책\n",
    "    doc_nouns = ''\n",
    "    print(nouns)\n",
    "\n",
    "    \n",
    "    for noun in nouns:\n",
    "        doc_nouns += noun + ' '   \n",
    "    doc_nouns_list.append(doc_nouns)\n",
    "    \n",
    "for i in range(0, 3):\n",
    "    print('doc' + str(i+1) + ' : ' + str(doc_nouns_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 분석을 위한 3x3 matrix를 만들었습니다.\n",
      "[[1.         0.19212486 0.56053185]\n",
      " [0.19212486 1.         0.4113055 ]\n",
      " [0.56053185 0.4113055  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(doc_nouns_list)\n",
    "\n",
    "document_distance = (tfidf_matrix * tfidf_matrix.T)\n",
    "\n",
    "print('유사도 분석을 위한 ' + str(documnet_distance.get_shape()[0]) + 'x' + str(documnet_distance.get_shape()[1]) + ' matrix를 만들었습니다.')\n",
    "print(document_distance.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Kkma, Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv</th>\n",
       "      <th>title</th>\n",
       "      <th>epi</th>\n",
       "      <th>dates</th>\n",
       "      <th>links</th>\n",
       "      <th>synop</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebs</td>\n",
       "      <td>다큐프라임</td>\n",
       "      <td>비밀의 땅 파미르  - 2부 비밀의 땅, 숨겨진 강</td>\n",
       "      <td>2018.09.11</td>\n",
       "      <td>http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...</td>\n",
       "      <td>아시아의 고산지대인 파미르, 텐샨,히말라야 의 자연과 사람들의 삶을 알아본다. 중앙...</td>\n",
       "      <td>늑대, 텐샨, 빙하, 고원, 저지대, 고지대, 사람들, 파미르, 야생동물</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ebs</td>\n",
       "      <td>다큐프라임</td>\n",
       "      <td>비밀의 땅 파미르 - 1부 세계의 지붕</td>\n",
       "      <td>2018.09.10</td>\n",
       "      <td>http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...</td>\n",
       "      <td>세계의 지붕 파미르에 서식하는 다양한 야생동물들의 생태소개 1부에서는 파미르에 서식...</td>\n",
       "      <td>늑대, 텐샨, 빙하, 고원, 저지대, 고지대, 사람들, 파미르, 야생동물</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ebs</td>\n",
       "      <td>다큐프라임</td>\n",
       "      <td>&lt;위대한 로마&gt; 제작노트 - 로마는 하루아침에 이루어지지 않았다</td>\n",
       "      <td>2018.09.05</td>\n",
       "      <td>http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...</td>\n",
       "      <td>위대한 로마의 촬영 기간은 총 6주로, 3주간 튀니지에서 재연 촬영을 했고 나머지...</td>\n",
       "      <td>로마, 폼페이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebs</td>\n",
       "      <td>다큐프라임</td>\n",
       "      <td>제국의 도시 - 폼페이</td>\n",
       "      <td>2018.09.04</td>\n",
       "      <td>http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...</td>\n",
       "      <td>폼페이를 첨단 그래픽과 3D 입체영상으로 완벽 복원한다.  콜로세움이 완성되어 가던...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ebs</td>\n",
       "      <td>다큐프라임</td>\n",
       "      <td>황제들의 정치무대 - 콜로세움</td>\n",
       "      <td>2018.09.03</td>\n",
       "      <td>http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...</td>\n",
       "      <td>로마 최대 원형경기장 콜로세움을 첨단 그래픽과 3D 입체영상으로 완벽 복원한다.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tv  title                                  epi       dates  \\\n",
       "0  ebs  다큐프라임         비밀의 땅 파미르  - 2부 비밀의 땅, 숨겨진 강  2018.09.11   \n",
       "1  ebs  다큐프라임                비밀의 땅 파미르 - 1부 세계의 지붕  2018.09.10   \n",
       "2  ebs  다큐프라임  <위대한 로마> 제작노트 - 로마는 하루아침에 이루어지지 않았다  2018.09.05   \n",
       "3  ebs  다큐프라임                         제국의 도시 - 폼페이  2018.09.04   \n",
       "4  ebs  다큐프라임                     황제들의 정치무대 - 콜로세움  2018.09.03   \n",
       "\n",
       "                                               links  \\\n",
       "0  http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...   \n",
       "1  http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...   \n",
       "2  http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...   \n",
       "3  http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...   \n",
       "4  http://www.ebs.co.kr/tv/show?courseId=BP0PAPB0...   \n",
       "\n",
       "                                               synop  \\\n",
       "0  아시아의 고산지대인 파미르, 텐샨,히말라야 의 자연과 사람들의 삶을 알아본다. 중앙...   \n",
       "1  세계의 지붕 파미르에 서식하는 다양한 야생동물들의 생태소개 1부에서는 파미르에 서식...   \n",
       "2   위대한 로마의 촬영 기간은 총 6주로, 3주간 튀니지에서 재연 촬영을 했고 나머지...   \n",
       "3  폼페이를 첨단 그래픽과 3D 입체영상으로 완벽 복원한다.  콜로세움이 완성되어 가던...   \n",
       "4       로마 최대 원형경기장 콜로세움을 첨단 그래픽과 3D 입체영상으로 완벽 복원한다.   \n",
       "\n",
       "                                        tag  \n",
       "0  늑대, 텐샨, 빙하, 고원, 저지대, 고지대, 사람들, 파미르, 야생동물  \n",
       "1  늑대, 텐샨, 빙하, 고원, 저지대, 고지대, 사람들, 파미르, 야생동물  \n",
       "2                                   로마, 폼페이  \n",
       "3                                       NaN  \n",
       "4                                       NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('tag_eb_songi_ver3.csv',encoding='cp949')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    아시아의 고산지대인 파미르, 텐샨,히말라야 의 자연과 사람들의 삶을 알아본다. 중앙...\n",
       "1    세계의 지붕 파미르에 서식하는 다양한 야생동물들의 생태소개 1부에서는 파미르에 서식...\n",
       "2     위대한 로마의 촬영 기간은 총 6주로, 3주간 튀니지에서 재연 촬영을 했고 나머지...\n",
       "3    폼페이를 첨단 그래픽과 3D 입체영상으로 완벽 복원한다.  콜로세움이 완성되어 가던...\n",
       "4         로마 최대 원형경기장 콜로세움을 첨단 그래픽과 3D 입체영상으로 완벽 복원한다.\n",
       "Name: synop, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=df['synop']\n",
    "sentence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma, Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아시아', '고산', '고산지대', '지대', '파', '파미르', '미르', '터', '히', '히말라야', '말라야', '의', '자연', '사람', '삶', '중앙', '중앙아시아', '거대', '호수', '아랄해', '지금', '20', '20세기', '세기', '최악', '환경', '환경재앙', '재앙', '곳', '2', '2부', '부', '물줄기', '다리아', '다리아강', '강', '과', '시', '시르다리아강', '르', '을', '발원지', '여정', '주요', '에피소드', '파미르고원', '고원', '대륙', '대륙빙하', '빙하', '중', '최대', '규모', '페드첸', '페드첸코', '코', '물', '판즈강', '키스', '아프가니스탄', '국경', '강인', '수', '프', '프가니스', '니스', '모습', '습지', '습지대까지', '대까지', '식생', '변화', '기대어', '소개', '산맥', '고도', '풍경', '자랑', '초록', '산', '색색', '꽃', '시르다리', '다리', '자일로', '여름', '목지', '유르트', '양', '키', '키르', '유목', '유목민', '민', '야생', '야생동물', '동물']\n"
     ]
    }
   ],
   "source": [
    "print(kkma.nouns(sentence[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아시아 고산 고산지대 지대 파 파미르 미르 터 히 히말라야 말라야 의 자연 사람 삶 중앙 중앙아시아 거대 호수 아랄해 지금 20 20세기 세기 최악 환경 환경재앙 재앙 곳 2 2부 부 물줄기 다리아 다리아강 강 과 시 시르다리아강 르 을 발원지 여정 주요 에피소드 파미르고원 고원 대륙 대륙빙하 빙하 중 최대 규모 페드첸 페드첸코 코 물 판즈강 키스 아프가니스탄 국경 강인 수 프 프가니스 니스 모습 습지 습지대까지 대까지 식생 변화 기대어 소개 산맥 고도 풍경 자랑 초록 산 색색 꽃 시르다리 다리 자일로 여름 목지 유르트 양 키 키르 유목 유목민 민 야생 야생동물 동물\n"
     ]
    }
   ],
   "source": [
    "mydoclist_kkma=[]\n",
    "nouns = ' '.join(kkma.nouns(sentence[0]))\n",
    "mydoclist_kkma.append(nouns)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아시아의 고산지대인 파미르, 텐샨,히말라야 의 자연과 사람들의 삶을 알아본다. 중앙아시아의 거대한 호수 ‘아랄해’, 지금은 거의 말라버려 20세기 최악의 환경재앙이라 불리는 곳입니다. 2부는 이 아랄해로 들어오는 두 물줄기 ‘아무다리아강’과 ‘시르다리아강’을 따라 그 발원지를 찾아가는 여정입니다.   <주요 에피소드> 아무다리아강의 발원지, 파미르고원 대륙빙하 중 최대 규모인 파미르의 페드첸코 빙하에서부터 녹아 흐르는 물은 판즈강을 거쳐 아무다리아 강이 된다. 타지키스탄과 아프가니스탄의 국경을 이루는 강인 판즈강을 따라 가면 쉽게 볼 수 없는 아프가니스탄 사람들의 모습을 볼 수 있다. 또 빙하부터 습지대까지 식생의 변화와, 환경의 변화를 살펴보고 강에 기대어 살아가는 사람들의 삶을 소개한다.   시르다리아강의 발원지는 텐샨산맥 파미르 고원에 비해 고도가 낮은 텐샨산맥은 아름다운 풍경을 자랑한다. 초록으로 뒤덮인 산과 색색의 꽃들은 화려한 텐샨을 만든다. 시르다리야강의 발원지인 텐샨의 빙하는 어떤 모습인지 소개한다. 자일로(여름 초목지)에 유르트를 짓고 양을 치는 키르기 유목민, 텐샨산맥의 야생동물을 만난다.  ',\n",
       " '세계의 지붕 파미르에 서식하는 다양한 야생동물들의 생태소개 1부에서는 파미르에 서식하는 다양한 야생동물과 파미르의 지역생태를 소개합니다. 그중에서도 특히 최고 포식자인 늑대를 중심으로 거친 생존의 현장을 보여줍니다. 늑대 이외에도 눈표범, 마르코폴로 양, 아이벡스, 수염수리 등 다양한 동물들이 어떤 관계를 맺으며 황량한 파미르에서 살아가는지를 소개합니다.   <주요 에피소드> 늑대와 인간 : 늑대의 먹이는 야생동물이지만 겨울이 오면 가축을 공격한다. 양, 염소, 야크와 같은 가축을 키우며 유목생활을 하는 파미르인들에게는 두려움과 원망의 대상이다. 유목민과 늑대의 이야기를 통해 이들의 적대적인 공존관계를 보여주고자 한다.   세계 최초 최상위 포식자들의 만남 눈표범과 늑대가 하나의 먹이를 두고 신경전을 벌인다. 그 어디에서도 보기 어려운 진귀한 광경으로 생생한 야생의 숨결을 느낄 수 있다. ??',\n",
       " ' 위대한 로마의 촬영 기간은 총 6주로, 3주간 튀니지에서 재연 촬영을 했고 나머지 3주는 이탈리아 로마, 폼페이에서 건축물 촬영을 했다. 촬영 기간은 6주이지만 제작기간은 2년인 위대한 로마는 그 커다란 규모만큼이나, 크고 작은 사건 사고들이 일어나 순탄치만은 않은 제작이었다. 3D 제작의 전 과정과 제작진들의 고뇌, 노하우를 공개한다.',\n",
       " \"폼페이를 첨단 그래픽과 3D 입체영상으로 완벽 복원한다.  콜로세움이 완성되어 가던 서기79년, 인구 2만명의 휴양 도시였던 폼페이는 갑작스런 화산폭 발로 순식간에 역사 속으로 사라진다. 2천년전 인류가 겪은 비극의 역사가 아이러니하게 현 대 고고학의 소중한 유산으로 남은 곳이 폼페이다. 로마의 역사는 폼페이를 통해 '황제중심' 에서 '민중중심'으로 그 무게중심이 옮겨지게 된다. 2천년전 로마인의 삶이 어떻게 이루어졌는지, 그 실상을 간직하고 있는곳!   로마인의 삶이 얼마나 정교하고 발달된 문명위에서 이루어졌는지, 특히 그들의 삶에 깊게 뿌 리를 내리고 있는 공공성은 우리가 살고 있는 현대의 그것과 비교해도 전혀 모자람이 없다는 사실은 우리를 놀라게 할 것이다\",\n",
       " '로마 최대 원형경기장 콜로세움을 첨단 그래픽과 3D 입체영상으로 완벽 복원한다.']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docu_list = [sentence[0], sentence[1], sentence[2], sentence[3], sentence[4]]\n",
    "docu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dayoi\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "twitter = Twitter()\n",
    "kkma = Kkma()\n",
    "\n",
    "mydoculist_kkma = []\n",
    "mydoculist_twitter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.08781464 0.01276021 0.         0.02371196 1.\n",
      "  0.08781464 0.01276021 0.         0.02371196 1.         0.08781464\n",
      "  0.01276021 0.         0.02371196 1.         0.08781464 0.01276021\n",
      "  0.         0.02371196]\n",
      " [0.08781464 1.         0.         0.01110031 0.         0.08781464\n",
      "  1.         0.         0.01110031 0.         0.08781464 1.\n",
      "  0.         0.01110031 0.         0.08781464 1.         0.\n",
      "  0.01110031 0.        ]\n",
      " [0.01276021 0.         1.         0.02647692 0.02323996 0.01276021\n",
      "  0.         1.         0.02647692 0.02323996 0.01276021 0.\n",
      "  1.         0.02647692 0.02323996 0.01276021 0.         1.\n",
      "  0.02647692 0.02323996]\n",
      " [0.         0.01110031 0.02647692 1.         0.25901492 0.\n",
      "  0.01110031 0.02647692 1.         0.25901492 0.         0.01110031\n",
      "  0.02647692 1.         0.25901492 0.         0.01110031 0.02647692\n",
      "  1.         0.25901492]\n",
      " [0.02371196 0.         0.02323996 0.25901492 1.         0.02371196\n",
      "  0.         0.02323996 0.25901492 1.         0.02371196 0.\n",
      "  0.02323996 0.25901492 1.         0.02371196 0.         0.02323996\n",
      "  0.25901492 1.        ]\n",
      " [1.         0.08781464 0.01276021 0.         0.02371196 1.\n",
      "  0.08781464 0.01276021 0.         0.02371196 1.         0.08781464\n",
      "  0.01276021 0.         0.02371196 1.         0.08781464 0.01276021\n",
      "  0.         0.02371196]\n",
      " [0.08781464 1.         0.         0.01110031 0.         0.08781464\n",
      "  1.         0.         0.01110031 0.         0.08781464 1.\n",
      "  0.         0.01110031 0.         0.08781464 1.         0.\n",
      "  0.01110031 0.        ]\n",
      " [0.01276021 0.         1.         0.02647692 0.02323996 0.01276021\n",
      "  0.         1.         0.02647692 0.02323996 0.01276021 0.\n",
      "  1.         0.02647692 0.02323996 0.01276021 0.         1.\n",
      "  0.02647692 0.02323996]\n",
      " [0.         0.01110031 0.02647692 1.         0.25901492 0.\n",
      "  0.01110031 0.02647692 1.         0.25901492 0.         0.01110031\n",
      "  0.02647692 1.         0.25901492 0.         0.01110031 0.02647692\n",
      "  1.         0.25901492]\n",
      " [0.02371196 0.         0.02323996 0.25901492 1.         0.02371196\n",
      "  0.         0.02323996 0.25901492 1.         0.02371196 0.\n",
      "  0.02323996 0.25901492 1.         0.02371196 0.         0.02323996\n",
      "  0.25901492 1.        ]\n",
      " [1.         0.08781464 0.01276021 0.         0.02371196 1.\n",
      "  0.08781464 0.01276021 0.         0.02371196 1.         0.08781464\n",
      "  0.01276021 0.         0.02371196 1.         0.08781464 0.01276021\n",
      "  0.         0.02371196]\n",
      " [0.08781464 1.         0.         0.01110031 0.         0.08781464\n",
      "  1.         0.         0.01110031 0.         0.08781464 1.\n",
      "  0.         0.01110031 0.         0.08781464 1.         0.\n",
      "  0.01110031 0.        ]\n",
      " [0.01276021 0.         1.         0.02647692 0.02323996 0.01276021\n",
      "  0.         1.         0.02647692 0.02323996 0.01276021 0.\n",
      "  1.         0.02647692 0.02323996 0.01276021 0.         1.\n",
      "  0.02647692 0.02323996]\n",
      " [0.         0.01110031 0.02647692 1.         0.25901492 0.\n",
      "  0.01110031 0.02647692 1.         0.25901492 0.         0.01110031\n",
      "  0.02647692 1.         0.25901492 0.         0.01110031 0.02647692\n",
      "  1.         0.25901492]\n",
      " [0.02371196 0.         0.02323996 0.25901492 1.         0.02371196\n",
      "  0.         0.02323996 0.25901492 1.         0.02371196 0.\n",
      "  0.02323996 0.25901492 1.         0.02371196 0.         0.02323996\n",
      "  0.25901492 1.        ]\n",
      " [1.         0.08781464 0.01276021 0.         0.02371196 1.\n",
      "  0.08781464 0.01276021 0.         0.02371196 1.         0.08781464\n",
      "  0.01276021 0.         0.02371196 1.         0.08781464 0.01276021\n",
      "  0.         0.02371196]\n",
      " [0.08781464 1.         0.         0.01110031 0.         0.08781464\n",
      "  1.         0.         0.01110031 0.         0.08781464 1.\n",
      "  0.         0.01110031 0.         0.08781464 1.         0.\n",
      "  0.01110031 0.        ]\n",
      " [0.01276021 0.         1.         0.02647692 0.02323996 0.01276021\n",
      "  0.         1.         0.02647692 0.02323996 0.01276021 0.\n",
      "  1.         0.02647692 0.02323996 0.01276021 0.         1.\n",
      "  0.02647692 0.02323996]\n",
      " [0.         0.01110031 0.02647692 1.         0.25901492 0.\n",
      "  0.01110031 0.02647692 1.         0.25901492 0.         0.01110031\n",
      "  0.02647692 1.         0.25901492 0.         0.01110031 0.02647692\n",
      "  1.         0.25901492]\n",
      " [0.02371196 0.         0.02323996 0.25901492 1.         0.02371196\n",
      "  0.         0.02323996 0.25901492 1.         0.02371196 0.\n",
      "  0.02323996 0.25901492 1.         0.02371196 0.         0.02323996\n",
      "  0.25901492 1.        ]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for docu in docu_list:\n",
    "    kkma_nouns = ' '.join(kkma.nouns(docu))\n",
    "    twitter_nouns = ' '.join(twitter.nouns(docu))\n",
    "    mydoculist_kkma.append(kkma_nouns)\n",
    "    mydoculist_twitter.append(twitter.nouns)\n",
    "    \n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix_kkma = tfidf_vectorizer.fit_transform(mydoculist_kkma)\n",
    "#tfidf_matrix_twitter = tfidf_vectorizer.fit_transform(mydoculist_twitter)\n",
    "\n",
    "document_distances_kkma = (tfidf_matrix_kkma * tfidf_matrix_kkma.T)\n",
    "#document_distances_twitter = (tfidf_matrix_twitter * tfidf_matrix_twitter.T)\n",
    "\n",
    "print(k)\n",
    "print(document_distances_kkma.toarray())\n",
    "\n",
    "\n",
    "print(' ')\n",
    "\n",
    "#print(document_distances_twitter.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
